## SVM

支持向量机（SVM）在神经网络出现之前内受青睐，由于使用的数学理论非常巧妙，并且这些数学理论很完善，具有可解释性强的特点SVM也是建模以及优化的优秀例子，值得学习。
SVM三宝：间隔对偶核技巧

具体来讲，我们为了保证分类器更好的分类效果，采用间隔评判分类器的分类能力；对偶是SVM最优化过程中重要步骤和思想，非常巧妙，也成为优化问题的重要思路；核技巧则是将SVM拓展到非线性问题，利用卷积核制造的维度差解决问题。

### 硬间隔分类

*关于行间公式：正常在github预览md文件行间公式无法正常显示，需要到chrome网上商店下载MathJax Plugin for Github；另外考虑到markdown和mathjax的差异，行间含大括号的公式在mathjax显示中需要四个\才能换行，而markdown需要2个即可，所以使用typora或者vscode查看时会多一行，但是不影响正常查看*

#### 线性可分

SVM通常来解决线性可分问题，线性可分的定义：
$D_0$ 和 $D_1$ 是 n 维欧氏空间中的两个点集。如果存在 n 维向量 w 和实数 b，使得所有属于 $D_0$ 的点 $x_i$ 都有 $wx_i+b>0$ ，而对于所有属于 $D_1$ 的点 $x_j$ 则有 $wx_i+b<0$ ，则我们称 $D_0$ 和 $D_0$ 线性可分。
直观地说，在一个棋盘（二维空间），可以划一条线将棋子分开；对一个蛋糕（三维平面），可以切一刀将蛋糕分成两部分；高维空间同理。
$wx_i+b=0$就形成了一个超平面

#### 最大间隔超平面
如下图，一个二维平面上有一群点，我们要一条线将其分为两部分，显然有无数条线符合条件，我们要选取其中的最大间隔的直线 ，在这里是$H_3$

<img src="https://amore.oss-cn-hangzhou.aliyuncs.com/img/svm1.png#x" style="zoom: 33%;" />

推广到多维空间也一样，只不过找的是一个最优超平面：

1. 两类样本分别在该超平面的两侧
2. 两侧距离超平面最近的样本点到超平面的距离最大

#### SVM最优化

SVM是至今学习的优化算法的比较难的，因为它用到的数学知识比较多，有些还没有学过，但是这些优化方法十分常见，学会这些优化方法也是学习SVM的收获。·· 
对于二维平面中直线 $Ax+By+C=0$，点(x,y)到直线距离公式：
$$D=\frac{|A x+B y+C|}{\sqrt{A^{2}+B^{2}}}$$
相应地，在n维空间内，点($x_1$,$x_2$,...,$x_n$)到直线$wx_i+b=0$距离为
$$D=\frac{\left|w^{T} x+b\right|}{\|w\|_2}$$ 
我们因此得到分段函数：
$$
\left\{\begin{array}{l}
\frac{w^{T} x+b}{\|w\|} \geq d \quad y=1 \\\\
\frac{w^{T} x+b}{\|w\|} \leq-d \quad y=-1
\end{array}\right.
$$ {1}
移项得：
$$
\left\{\begin{array}{l}
\frac{w^{T} x+b}{\|w\| d} \geq 1 \quad y=1 \\\\
\frac{w^{T} x+b}{\|w\| d} \leq-1 \quad y=-1
\end{array}\right.
$$
因为 $\|w\| d$ 是正数，所以我们令它等于1，相当于将间隔放缩，不会影响到结果，并且可以简化运算:
$$
\left\lbrace\begin{array}{l}
w^{T} x+b \geq 1 \quad y=1 \\
w^{T} x+b \leq-1 \quad y=-1
\end{array}\right.
$$
等价于
$$
y(w^{T} x+b) \geq 1
$$
需要注意这个式子的意义是正确分类的条件，我们因此也得到了超平面，如下图（图片来源：Bing图片）：

<img src="https://amore.oss-cn-hangzhou.aliyuncs.com/img/SVM2.png" style="zoom: 50%;" />

对于间隔分类我的简单理解：对于
